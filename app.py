# -*- coding: utf-8 -*-
"""Multi-Role LLM System for SQL Query Execution and PDF Report Generation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MY8Q5tGEcns2exOvO-vAjOFsQVmLpy-w
"""


import sqlite3

conn = sqlite3.connect("shop.db", check_same_thread=False)

# Create users table with AUTOINCREMENT for the id field
conn.execute('''
CREATE TABLE IF NOT EXISTS users (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT,
    email TEXT,
    signup_date DATE
)
''')

# Create orders table with AUTOINCREMENT for the id field
conn.execute('''
CREATE TABLE IF NOT EXISTS orders (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id INTEGER,
    amount REAL,
    status TEXT,
    order_date DATE,
    FOREIGN KEY(user_id) REFERENCES users(id)
)
''')

# Insert users without specifying the id (SQLite will handle it)
conn.execute("INSERT INTO users (name, email, signup_date) VALUES ('Alice', 'alice@example.com', '2024-01-10')")
conn.execute("INSERT INTO users (name, email, signup_date) VALUES ('Bob', 'bob@example.com', '2024-03-15')")
conn.execute("INSERT INTO users (name, email, signup_date) VALUES ('Charlie', 'charlie@example.com', '2024-03-22')")
conn.execute("INSERT INTO users (name, email, signup_date) VALUES ('Diana', 'diana@example.com', '2024-04-05')")
conn.execute("INSERT INTO users (name, email, signup_date) VALUES ('Eve', 'eve@example.com', '2024-04-25')")
conn.execute("INSERT INTO users (name, email, signup_date) VALUES ('Frank', 'frank@example.com', '2024-05-15')")
conn.execute("INSERT INTO users (name, email, signup_date) VALUES ('Grace', 'grace@example.com', '2024-05-18')")
conn.execute("INSERT INTO users (name, email, signup_date) VALUES ('Henry', 'henry@example.com', '2024-05-20')")
conn.execute("INSERT INTO users (name, email, signup_date) VALUES ('Ivy', 'ivy@example.com', '2024-06-01')")
conn.execute("INSERT INTO users (name, email, signup_date) VALUES ('Jack', 'jack@example.com', '2024-06-05')")
conn.execute("INSERT INTO users (name, email, signup_date) VALUES ('Kiran', 'kiran@example.com', '2024-06-03')")
conn.execute("INSERT INTO users (name, email, signup_date) VALUES ('Lata', 'lata@example.com', '2024-06-04')")
conn.execute("INSERT INTO users (name, email, signup_date) VALUES ('Manoj', 'manoj@example.com', '2024-06-06')")

# Insert orders without specifying the id (SQLite will handle it)
conn.execute("INSERT INTO orders (user_id, amount, status, order_date) VALUES (1, 250.00, 'completed', '2024-03-10')")
conn.execute("INSERT INTO orders (user_id, amount, status, order_date) VALUES (2, 100.00, 'pending', '2024-03-16')")
conn.execute("INSERT INTO orders (user_id, amount, status, order_date) VALUES (3, 320.00, 'completed', '2024-03-24')")
conn.execute("INSERT INTO orders (user_id, amount, status, order_date) VALUES (4, 180.00, 'completed', '2024-05-01')")
conn.execute("INSERT INTO orders (user_id, amount, status, order_date) VALUES (5, 210.00, 'completed', '2024-05-02')")
conn.execute("INSERT INTO orders (user_id, amount, status, order_date) VALUES (1, 180.00, 'completed', '2024-03-18')")
conn.execute("INSERT INTO orders (user_id, amount, status, order_date) VALUES (2, 120.00, 'completed', '2024-03-20')")
conn.execute("INSERT INTO orders (user_id, amount, status, order_date) VALUES (1, 300.00, 'completed', '2024-04-01')")
conn.execute("INSERT INTO orders (user_id, amount, status, order_date) VALUES (3, 80.00, 'cancelled', '2024-04-10')")
conn.execute("INSERT INTO orders (user_id, amount, status, order_date) VALUES (4, 250.00, 'pending', '2024-05-05')")
conn.execute("INSERT INTO orders (user_id, amount, status, order_date) VALUES (6, 400.00, 'completed', '2024-05-20')")
conn.execute("INSERT INTO orders (user_id, amount, status, order_date) VALUES (7, 320.00, 'completed', '2024-05-22')")
conn.execute("INSERT INTO orders (user_id, amount, status, order_date) VALUES (8, 150.00, 'pending', '2024-05-25')")
conn.execute("INSERT INTO orders (user_id, amount, status, order_date) VALUES (9, 220.00, 'completed', '2024-06-02')")
conn.execute("INSERT INTO orders (user_id, amount, status, order_date) VALUES (10, 500.00, 'completed', '2024-06-06')")

conn.commit()


from langchain_core.tools import tool


@tool
def get_schema() -> str:
  """Returns table schemas from the SQLite database"""
  schema = ""
  for table in ["users", "orders"]:
    rows = conn.execute(f"PRAGMA table_info({table})").fetchall()
    cols = ",".join([f"{r[1]} {r[2]}" for r in rows])
    schema += f"{table}({cols})\n"
  return schema.strip()

@tool
def execute_sql(query: str) -> str:
  """Executes SQL query on the database and return the result"""
  try:
    result = conn.execute(query).fetchall()
    return str(result)
  except Exception as e:
    return f"Error: {str(e)}"

from langgraph.graph import StateGraph, END, START
from langgraph.graph.message import AnyMessage, add_messages
from langgraph.prebuilt import ToolNode, create_react_agent

from langchain_openai import ChatOpenAI

from typing import Annotated, TypedDict
from langgraph.prebuilt import tools_condition
from langchain_core.messages import AIMessage, SystemMessage, HumanMessage

import os

os.environ["OPENAI_API_KEY"] = ""

llm = ChatOpenAI(model="gpt-4o-mini")

#analyst agent

analyst_llm = llm.bind_tools([get_schema])

analyst_system_message = [SystemMessage(content="""You are a data analyst. Start by understanding the database schema using tools.
    Then ask at least 10 insightful questions in a single response that will help in creating a comprehensive report.
    """)]

class AnalystState(TypedDict):
  messages: Annotated[list[AnyMessage], add_messages]

def analyst(state: AnalystState) -> AnalystState:
  response = analyst_llm.invoke(analyst_system_message + state["messages"])
  return {"messages": [response]}


analyst_graph = StateGraph(AnalystState)
analyst_graph.add_node("analyst", analyst)
analyst_graph.add_node("tools", ToolNode([get_schema]))

analyst_graph.add_edge(START, "analyst")
analyst_graph.add_conditional_edges("analyst", tools_condition)
analyst_graph.add_edge("tools","analyst")

analyst_app = analyst_graph.compile()

from IPython.display import Image, display

display(Image(analyst_app.get_graph().draw_mermaid_png()))

result = analyst_app.invoke({"messages": [HumanMessage("")]})
print(result["messages"][-1].content)

#expert agent

expert_llm = llm.bind_tools([get_schema, execute_sql])

expert_system_message = [SystemMessage(content="""You are a data expert.
Use tools to answer the analyst's questions by querying the database.
you do not have to summarize it. Later reviwer will do that.""")]

class ExpertState(TypedDict):
  messages: Annotated[list[AnyMessage], add_messages]

def expert(state: ExpertState) -> ExpertState:
  response = expert_llm.invoke(expert_system_message + state["messages"])
  return {"messages": [response]}


expert_graph = StateGraph(ExpertState)
expert_graph.add_node("expert", expert)
expert_graph.add_node("tools", ToolNode([get_schema, execute_sql]))

expert_graph.add_edge(START, "expert")
expert_graph.add_conditional_edges("expert", tools_condition)
expert_graph.add_edge("tools","expert")

expert_app = expert_graph.compile()

from IPython.display import Image, display

display(Image(expert_app.get_graph().draw_mermaid_png()))


from langchain.tools import tool

@tool
def generate_pdf_report(text: str, filename: str = "my_report.pdf") -> str:
    """
    Converts the provided text summary into a downloadable PDF report.
    Returns the file path.
    """
    from fpdf import FPDF
    import os

    try:
        pdf = FPDF()
        pdf.add_page()
        pdf.set_auto_page_break(auto=True, margin=15)
        pdf.set_font("Arial", size=12)

        for line in text.split("\n"):
            pdf.multi_cell(0, 10, line)

        # Save the file
        file_path = f"/content/sample_data/{filename}"
        pdf.output(file_path)
        return file_path
    except Exception as e:
        return f"PDF generation failed: {str(e)}"

#reviwer agent


reviewer_llm = llm

reviewer_system_message = [SystemMessage(content="""You are an expert reviewer tasked with summarizing detailed database analysis reports.
Your goal is to produce a concise and clear summary in exactly eight lines.
Focus on key insights such as user count and growth, order statistics, top performers, and actionable recommendations.
Avoid repeating detailed tables or lists; instead, synthesize the information to highlight the main takeaways.
Keep the language simple and professional.
Make sure the summary is polished, easy to understand, and ready for presentation as a PDF document.
Give 2 actionable insights at the end to conclude
""")]

class ReviewerState(TypedDict):
  messages: Annotated[list[AnyMessage], add_messages]

def reviewer(state: ReviewerState) -> ReviewerState:
  response = reviewer_llm.invoke(reviewer_system_message + state["messages"])
  return {"messages": [response]}


reviewer_graph = StateGraph(ReviewerState)
reviewer_graph.add_node("reviewer", reviewer)
reviewer_graph.add_edge(START, "reviewer")

reviewer_app = reviewer_graph.compile()









from IPython.display import Image, display

display(Image(reviewer_app.get_graph().draw_mermaid_png()))

# define the supervisor

from pydantic import BaseModel, Field
from typing import Literal

class AgentSelector(BaseModel):
  """Route to the available agent if needed, else route to END"""
  next_node: Literal["analyst","expert","reviewer","END"] = Field(
      description = "Route to the available agent if needed, else route to END"
  )

llm = ChatOpenAI(model="gpt-4o-mini")
agent_selector_llm = llm.with_structured_output(AgentSelector)

supervisor_system_message = [SystemMessage(content="""
You are a supervisor agent in charge of orchestrating three roles: [analyst, expert, and reviewer].

1. The **analyst** explores the database schema and raises insightful questions.
2. The **expert** answers these questions using SQL tools on the database.
3. The **reviewer** summarizes the expert‚Äôs answers into a polished report.

At each step:
- Set the 'next_node' to one of: 'analyst', 'expert', 'reviewer', or 'END'.
- First, route to the analyst to begin exploration.
- Once enough questions are asked, route to the expert to answer them.
- After answering, route to the reviewer to summarize everything.
- Finally, route to 'END' when the process is complete.

It is mandatory to go to each of the node atleast once.

Do not perform the tasks yourself. Your job is only to **coordinate** and **decide** the next best agent to handle the task.
""")]

class SupervisorState(TypedDict):
  messages: Annotated[list[AnyMessage], add_messages]
  next_node: Literal["analyst","expert","reviewer","END"]



def supervisor(state: SupervisorState) -> SupervisorState:
    response = agent_selector_llm.invoke(
        supervisor_system_message + state["messages"]
    )
    return {
        "next_node": response.next_node
    }


def route_from_supervisor(state: SupervisorState) -> Literal["analyst","expert","reviewer","__end__"]:
  """
  Route based on the supervisors decision.
  It reads the next_node key from the supervisor state.
  """
  next_node = state.get("next_node")
  if next_node == "END":
    return "__end__"
  else:
    return next_node

graph = StateGraph(SupervisorState)
graph.add_node("supervisor", supervisor)
graph.add_node("analyst", analyst_app)
graph.add_node("expert", expert_app)
graph.add_node("reviewer", reviewer_app)

graph.add_edge(START, "supervisor")
graph.add_conditional_edges("supervisor", route_from_supervisor)
graph.add_edge("analyst","supervisor")
graph.add_edge("expert","supervisor")
graph.add_edge("reviewer","supervisor")

final_app = graph.compile()

from IPython.display import Image, display

display(Image(final_app.get_graph().draw_mermaid_png()))

from langchain_core.messages import HumanMessage

inputs = {
    "messages": [
        HumanMessage(content="Generate a summary report based on tables in my database.")
    ]
}


for output in final_app.stream(inputs):
    for key, value in output.items():
        print("=" * 50)
        print(f"üìç Node: {key}")
        print("-" * 50)

        if "messages" in value:
            for msg in value["messages"]:
                print(f"{msg.type.upper()}: {msg.content}\n")
        else:
            print("(no messages)")

        print("=" * 50)


# =========================
# STREAMLIT UI (app.py)
# =========================
import streamlit as st
from PIL import Image
import io
from langchain_core.messages import HumanMessage
from fpdf import FPDF

st.set_page_config(page_title="Multi-Role LLM SQL ‚Üí PDF", layout="wide")
st.title("Multi-Role LLM System (Analyst ‚Üí Expert ‚Üí Reviewer) | SQL + PDF")

# --------- Workflow Graph ----------
st.subheader("Workflow Graph")
try:
    graph_png = final_app.get_graph().draw_mermaid_png()  # <- use final_app (your compiled graph)
    st.image(graph_png, caption="LangGraph Workflow", width=650)
except Exception as e:
    st.warning(f"Could not render workflow graph: {e}")

st.divider()

# --------- Helper: Run the multi-agent system ----------
def run_multi_agent(question: str) -> str:
    """
    Runs your LangGraph multi-agent pipeline and returns the final text output.
    """
    inputs = {"messages": [HumanMessage(content=question)]}
    result = final_app.invoke(inputs)   # <- backend execution (no intermediate steps shown)
    return result["messages"][-1].content

# --------- Helper: Generate PDF bytes ----------
def make_pdf_bytes(text: str) -> bytes:
    pdf = FPDF()
    pdf.add_page()
    pdf.set_auto_page_break(auto=True, margin=15)
    pdf.set_font("Arial", size=12)

    for line in text.split("\n"):
        pdf.multi_cell(0, 8, line)

    # Return PDF as bytes
    return pdf.output(dest="S").encode("latin-1")

# --------- Question + Answer ----------
st.subheader("Ask a Question")
question = st.text_input("Enter your question (example: Generate a summary report based on tables in my database)")

answer = None
if st.button("Run", type="primary", use_container_width=False) and question.strip():
    with st.spinner("Running Analyst ‚Üí Expert ‚Üí Reviewer..."):
        answer = run_multi_agent(question.strip())
    st.success("Done!")

if answer:
    st.subheader("Answer")
    st.write(answer)

    st.subheader("Download Report (PDF)")
    pdf_bytes = make_pdf_bytes(answer)
    st.download_button(
        label="Download PDF Report",
        data=pdf_bytes,
        file_name="report.pdf",
        mime="application/pdf",
        use_container_width=False
    )

